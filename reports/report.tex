% Instructions and evaluation guidelines
% Students can work in groups of maximum 3 students.
% Each group must write a short (1-2 pages) research project proposal. It should include a description of a minimum viable project, the data you will use or collect, the computing resources you think you will need, some nice-to-haves if time allows, and a short review of related work. Project proposals must be approved before working on the project.
% Towards the end of the class, you will submit a project report (around 8 pages), in the format of a machine learning conference paper which has to include the following sections:

%%% Introduction: which states the problem which has been tackled

%%% Related Work: which covers research that is related to the considered problem

%%% Methods: a clear and detailed description of the neural networks (architecture, training-parameters, loss function, data)

%%% Results:
   % qualitative analysis: could include examples of generated images, correct vs wrong predictions, ...
   % quantitative analysis: general overview of final performance, loss curves, comparison table with error-bars, ...
%%% Discussion: a critical discussion of the performance of the neural network, analysis of the potential limitations, tips for future work

% The grade will depend on two main components:
%%% quality and originality of the project (are the contributions of the group to the development of the project well defined? what has been implemented with respect to the original research questions, what has been re-used from existing coding directories?)
%%% presentation of the project (structure of the report, clarity of figures/tables, correctness of the English language)

% Both the project proposal and the project report should follow the LaTex template template-report.tex. Feel free to change the structure of the latex template if needed.
% Honor code

%% You may consult papers, books, online references, or publicly available implementations for ideas that you may want to adapt and incorporate into your project, so long as you clearly cite your sources in your code and your writeup. However, under no circumstances, may you base your project on someone else's implementation. One of the main learning outcomes of this project is indeed for you to gain experience in designing and implementing a deep learning system by yourself.

% If you are combining your course project with the project from another class, you must receive permission from the instructors, and clearly explain in the proposal, final report the exact portion of the project that is being counted for INFO8010. In this case you must prepare separate reports for each course, and submit your final report for the other course as well.







% ==================== Ayoub Notes  ============================================

% convolution layers in patch embedding is helps extracting local features/dependencies, which is suitable for our case, as cancer usualy located in one 
% image preprocessing: The MRI images were preprocessed by cropping out the surrounding black space, ensuring that only the Region of Interest (ROI) is retained, which  reduces unnecessary background noise, and better resize :
% torchvision.transforms.RandomResizedCrop is not used, to not accidently exclude cancerious regions, ((negative/positive) bias??) 


ViT is competetive for large datasets, but for small ones like the one we have, CNN converges faster and achieves 'better results' (accuracy $95.5\%$), even after data augmentation, Vit never hits the barre of $90\%$

here is the architecture tree that we have made:


% coversation: https://github.com/google-research/vision_transformer/issues/61#issuecomment-802233921
%Question title: Is the extra class embedding important to predict the results, why not simply use feature maps to predict? #61

% Different from the common ways to use feature maps to obtain classifcation prediction (with fc or GAP layers), VIT employs an extra class embedding to do this without using feature maps explicitly. Wonder the meanings of this unusual design?
% BTW, I used official pre-training params to fine-tune VIT on a small dataset, found that the validation accuracy is a little better after I replaced the feature maps with leanable class embedding to predict. So is the class embedding (maybe like a kind of query within encoder) important to learn and to predict?

% Lucas Beyer %%Great question. It is not really important. However, we wanted the model to be "exactly Transformer, but on image patches", so we kept this design from Transformer, where a token is always used.